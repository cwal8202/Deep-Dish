{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae42ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  EfficientNet-B0 기반 이진분류 모델 만들기 + 전이학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06363cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한것 import \n",
    "\n",
    "import os\n",
    "import torch\n",
    "import copy\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 디바이스 설정 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "#이미지 전처리\n",
    "transform = transform.Compose([\n",
    "    transforms.Resize((224,224)), # 사이즈 조정 - efficientnet은 기본 224로 맞춰짐, 다 같이 맞춰야 함\n",
    "    transforms.ToTensor(),        # tensor 변환 numpy 배열을 pytorch tensor로 변환 (0~1)정규화  \n",
    "    transforms.Normalize([0.485,0.456,0.406],  # 정규화(mean)\n",
    "                         [0.229.0.224,0.225]) # 정규화(std)\n",
    "])\n",
    "\n",
    "\n",
    "# 예측 함수 정의 (외부에서도 사용 가능)\n",
    "def predict_image_from_url(image_url, threshold=0.5):\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "            prob = torch.sigmoid(output).item()\n",
    "\n",
    "        if prob > threshold:\n",
    "            print(f\"이미지 예측 결과: 햄버거 (확률: {prob:.4f})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"이미지 예측 결과: 비햄버거 (확률: {prob:.4f})\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"예측 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 그래프 저장 함수\n",
    "def save_training_graph(train_acc_list, val_acc_list, train_loss_list, save_path=\"training_result.png\"):\n",
    "    epochs = range(1, len(train_acc_list) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_acc_list, label='Train Acc')\n",
    "    plt.plot(epochs, val_acc_list, label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_loss_list, label='Train Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 경로\n",
    "    data_dir = \"C:/Users/baby3/OneDrive/바탕 화면/햄버거 테스트용/model_data\"    \n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    train_ds = datasets.ImageFolder(os.path.join(data_dir,\"train\"),transform=transform)\n",
    "    val_ds = datasets.ImageFolder(os.path.join(data_dir,\"val\"), transform=transform)\n",
    "    test_ds = datasets.ImageFolder(os.path.join(data_dir,\"test\"),transform=transform)\n",
    "\n",
    "    #배치사이즈 : 한번에 학습하는 이미지 , 일반적으로 16,32,64 \n",
    "    # shuffle = True는 훈련 데이터의 순서를 매 epoch마다 랜덤하게 섞는다는 뜻\n",
    "    train_loder = DataLoader(train_ds,batch_size=32, shuffle=True) \n",
    "    train_loder = DataLoader(train_ds,batch_size=32, shuffle=False)\n",
    "    train_loder = DataLoader(train_ds,batch_size=32, shuffle=False)\n",
    "\n",
    "    # EfficientNet-B0 모델 불러오기 \n",
    "    model = models.efficientent_b0(pretrained=True)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(1280, 1))\n",
    "        # model.classifier[1] = nn.Linear(in_features=1280, out_features=1)  # 이진 분류 \n",
    "        # 맨 마지막 분류기 바꿔서 ↑ / sigmoid 는 내부적으로 하는것. \n",
    "    model = model.to(device)\n",
    "\n",
    "    # 손실함수 & 옵티마이저 \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # EarlyStopping & 최고 모델 저장 준비\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_acc = 0\n",
    "    early_stop_count = 0\n",
    "    early_stop_patience = 10  #10번 정체면 저장\n",
    "\n",
    "    # epoch 저장 (기록용 리스트)\n",
    "    train_acc_list = []\n",
    "    val_caa_list = []\n",
    "    train_loss_list = []\n",
    "\n",
    "    # 학습 루프\n",
    "    epochs = 30\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_acc_list.append(train_acc)\n",
    "        train_loss_list.append(running_loss)\n",
    "\n",
    "        # 검증\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                outputs = model(inputs)\n",
    "                preds = torch.sigmoid(outputs) > 0.5\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_acc = correct / total\n",
    "        val_acc_list.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}  Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # 최고 성능 모델 저장\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), \"best_burger_model.pth\")\n",
    "            print(\"모델 저장됨 (최고 성능)\")\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "            print(f\"EarlyStopping 대기 중... ({early_stop_count}/{early_stop_patience})\")\n",
    "\n",
    "        if early_stop_count >= early_stop_patience:\n",
    "            print(\"Early stopping 발생!\")\n",
    "            break\n",
    "\n",
    "    # 최고 성능 모델로 복원\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(\"최고 모델로 복원 완료\")\n",
    "\n",
    "    # 테스트 정확도 확인\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"최종 테스트 정확도: {correct / total:.4f}\")\n",
    "\n",
    "    # 그래프 저장\n",
    "    save_training_graph(train_acc_list, val_acc_list, train_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74829d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b0 모델 예측 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predict.py\n",
    "\n",
    "from predict import predict_image_from_url\n",
    "\n",
    "# 예측하고 싶은 이미지 URL\n",
    "url = \"https://example.com/sample.jpg\"\n",
    "\n",
    "# 예측 실행\n",
    "predict_image_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30727151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
